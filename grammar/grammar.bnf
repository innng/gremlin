<start> ::= <preprocessing> | <classification> | <ensemble>

<preprocessing> ::= <attributeSelection> <classification>
                  | <attributeSelection> <ensemble>
<classification> ::= <metaClassifier> <baseClassifier>
                   | <baseClassifier>
<ensemble> ::= <ensembleClassifier>

<attributeSelection> ::= <AttributeSelectedClassifier> <eval> <search>
<metaClassifier> ::= <LWL> | <AdaBoostM1> | <Bagging> | <RandomCommittee>
                   | <RandomSubSpace>
<baseClassifier> ::= <BayesNet> | <NaiveBayes> | <NaiveBayesMultinomial>
                   | <Logistic> | <MultiLayerPerceptron> | <SGD> | <SimpleLogistic>
                   | <SMO> | <VotedPerceptron> | <IBk> | <KStar> | <DecisionTable>
                   | <JRip> | <OneR> | <PART> | <ZeroR> | <DecisionStump> | <J48>
                   | <LMT> | <RandomForest> | <RandomTree> | <REPTree>
<ensembleClassifier> ::= <Stacking> | <Vote>

<eval> ::= <CfsSubsetEval>
<search> ::= <BestFirst> | <GreedyStepwise>

<CfsSubsetEval> ::= "CfsSubsetEval "

<BestFirst> ::= "BestFirst "

<GreedyStepwise> ::= "GreedyStepwise "

<AttributeSelectedClassifier> ::= "AttributeSelectedClassifier "

<LWL> ::= "LWL "

<AdaBoostM1> ::= "AdaBoostM1 "

<Bagging> ::= "Bagging "

<RandomCommittee> ::= "RandomCommittee "

<RandomSubSpace> ::= "RandomSubSpace "

<BayesNet> ::= "BayesNet "

<NaiveBayes> ::= "NaiveBayes "

<NaiveBayesMultinomial> ::= "NaiveBayesMultinomial "

<Logistic> ::= "Logistic "

<MultiLayerPerceptron> ::= "MultiLayerPerceptron "
                           "B "<MultiLayerPerceptron-nominalToBinaryFilter>
                           "D "<MultiLayerPerceptron-decay>
                           "H "<MultiLayerPerceptron-hiddenLayers>
                           "L "<MultiLayerPerceptron-learningRate>
                           "M "<MultiLayerPerceptron-momentum>
                           "R "<MultiLayerPerceptron-reset>
<MultiLayerPerceptron-nominalToBinaryFilter> ::= "TRUE " | "FALSE "
<MultiLayerPerceptron-decay> ::= "TRUE " | "FALSE "
<MultiLayerPerceptron-hiddenLayers> ::= "RANDOM_INT [1, 4] "
<MultiLayerPerceptron-learningRate> ::= "RANDOM_FLOAT [0.1, 1] "
<MultiLayerPerceptron-momentum> ::= "RANDOM_FLOAT [0, 1] "
<MultiLayerPerceptron-reset> ::= "TRUE " | "FALSE "

<SGD> ::= "SGD " "F "<SGD-lossFunction> "L "<SGD-learningRate>
          "M "<SGD-dontReplaceMissing> "N "<SGD-dontNormalize> "R "<SGD-lambda>
<SGD-lossFunction> ::= "RANDOM_INT [0, 2] "
<SGD-learningRate> ::= "RANDOM_FLOAT [0.00001, 0.1] "
<SGD-dontReplaceMissing> ::= "TRUE " | "FALSE "
<SGD-dontNormalize> ::= "TRUE " | "FALSE "
<SGD-lambda> ::= "RANDOM_FLOAT [1e-12, 10] "

<SimpleLogistic> ::= "SimpleLogistic "

<SMO> ::= "SMO " "C "<SMO-cost> "K "<SMO-kernel> "M "<SMO-buildCalibrationModels>
          "N "<SMO-filterType>
<SMO-cost> ::= "RANDOM_FLOAT [0.5, 1.5] "
<SMO-kernel> ::= <NormalizedPolyKernel> | <PolyKernel> | <Puk> | <RBFKernel>
<SMO-buildCalibrationModels> ::= "TRUE " | "FALSE "
<SMO-filterType> ::= "RANDOM_INT [0, 2] "

<NormalizedPolyKernel> ::= "E "<NormalizedPolyKernel-exponent>
                           "L "<NormalizedPolyKernel-useLowerOrder>
<NormalizedPolyKernel-exponent> ::= "RANDOM_FLOAT [0.2, 5] "
<NormalizedPolyKernel-useLowerOrder> ::= "TRUE " | "FALSE "

<PolyKernel> ::= "E "<PolyKernel-exponent> "L "<PolyKernel-useLowerOrder>
<PolyKernel-exponent> ::= "RANDOM_FLOAT [0.2, 5] "
<PolyKernel-useLowerOrder> ::= "TRUE " | "FALSE "

<Puk> ::= "O "<Puk-omega> "S "<Puk-sigma>
<Puk-omega> ::= "RANDOM_FLOAT [0.1, 1] "
<Puk-sigma> ::= "RANDOM_FLOAT [0.1, 10] "

<RBFKernel> ::= "G "<RBFKernel-gamma>
<RBFKernel-gamma> ::= "RANDOM_FLOAT [0.0001, 1] "

<VotedPerceptron> ::= "VotedPerceptron " "E "<VotedPerceptron-exponent>
                      "I "<VotedPerceptron-numIterations> "M "<VotedPerceptron-maxK>
<VotedPerceptron-exponent> ::= "RANDOM_FLOAT [0.2, 5] "
<VotedPerceptron-numIterations> ::= "RANDOM_INT [1, 10] "
<VotedPerceptron-maxK> ::= "RANDOM_INT [5000, 50000] "

<IBk> ::= "IBk "

<KStar> ::= "KStar "

<DecisionTable> ::= "DecisionTable " "E "<DecisionTable-evaluationMeasure>
                    "I "<DecisionTable-useIBk> "S "<DecisionTable-search>
                    "X "<DecisionTable-crossVal>
<DecisionTable-evaluationMeasure> ::= "RANDOM_INT [1, 4] "
<DecisionTable-useIBk> ::= "TRUE " | "FALSE "
<DecisionTable-search> ::= "RANDOM_INT [1, 2] "
<DecisionTable-crossVal> ::= "RANDOM_INT [1, 4] "

<JRip> ::= "JRip " "E "<JRip-checkErrorRate> "N "<JRip-minNo> "O "<JRip-optimizations>
           "P "<JRip-usePruning>
<JRip-checkErrorRate> ::= "TRUE " | "FALSE "
<JRip-minNo> ::= "RANDOM_FLOAT [1, 5] "
<JRip-optimizations> ::= "RANDOM_INT [1, 5] "
<JRip-usePruning> ::= "TRUE " | "FALSE "

<OneR> ::= "OneR " "B "<OneR-minBucketSize>
<OneR-minBucketSize> ::= "RANDOM_INT [1, 32] "

<PART> ::= "PART " "B "<PART-binarySplits> "M "<PART-minNumObj>
           "R "<PART-reducedErrorPruning>
<PART-binarySplits> ::= "TRUE " | "FALSE "
<PART-minNumObj> ::= "RANDOM_INT [1, 64] "
<PART-numFolds> ::= "RANDOM_INT [2, 5] "
<PART-reducedErrorPruning> ::= "TRUE " "N "<PART-numFolds> | "FALSE "

<ZeroR> ::= "ZeroR "

<DecisionStump> ::= "DecisionStump "

<J48> ::= "J48 " "A "<J48-useLaplace> "B "<J48-binarySplits>
          "J "<J48-useMDLcorrection> "M "<J48-minNumObj> "O "<J48-collapseTree>
          "U "<J48-unpruned>
<J48-useLaplace> ::= "TRUE " | "FALSE "
<J48-binarySplits> ::= "TRUE " | "FALSE "
<J48-confidenceFactor> ::= "RANDOM_FLOAT [0, 1] "
<J48-useMDLcorrection> ::= "TRUE " | "FALSE "
<J48-minNumObj> ::= "RANDOM_INT [1, 64] "
<J48-collapseTree> ::= "TRUE " | "FALSE "
<J48-subtreeRaising> ::= "TRUE " | "FALSE "
<J48-unpruned> ::= "TRUE " | "FALSE " "C "<J48-confidenceFactor>
                   "S "<J48-subtreeRaising>

<LMT> ::= "LMT " "A "<LMT-useAIC> "B "<LMT-convertNominal> "C "<LMT-fastRegression>
          "P "<LMT-errorOnProbabilities> "R "<LMT-splitOnResiduals>
          "W "<LMT-weightTrimBeta>
<LMT-useAIC> ::= "TRUE " | "FALSE "
<LMT-convertNominal> ::= "TRUE " | "FALSE "
<LMT-fastRegression> ::= "TRUE " | "FALSE "
<LMT-errorOnProbabilities> ::= "TRUE " | "FALSE "
<LMT-splitOnResiduals> ::= "TRUE " | "FALSE "
<LMT-weightTrimBeta> ::= "0 " | "RANDOM_FLOAT [0, 1] "

<RandomForest> ::= "RandomForest " "I "<RandomForest-numIterations>
                   "K "<RandomForest-numFeatures> "MD "<RandomForest-maxDepth>
<RandomForest-numIterations> ::= "RANDOM_INT [2, 256] "
<RandomForest-numFeatures> ::= "0 " | "RANDOM_INT [1, 32] "
<RandomForest-maxDepth> ::= "0 " | "RANDOM_INT [1, 20]"

<RandomTree> ::= "RandomTree " "K "<RandomTree-KValue> "M "<RandomTree-minNum>
                 "N "<RandomTree-numFolds> "MD "<RandomTree-maxDepth>
<RandomTree-KValue> ::= "0 " | "RANDOM_INT [2, 32] "
<RandomTree-minNum> ::= "RANDOM_INT [1, 64] "
<RandomTree-numFolds> ::= "0 " | "RANDOM_INT [2, 5] "
<RandomTree-maxDepth> ::= "0 " | "RANDOM_INT [2, 20] "

<REPTree> ::= "REPTree " "L "<REPTree-maxDepth> "M "<REPTree-minNum>
              "P "<REPTree-noPruning>
<REPTree-maxDepth> ::= "-1 " | "RANDOM_INT [2, 20] "
<REPTree-minNum> ::= "RANDOM_INT [1, 64] "
<REPTree-noPruning> ::= "TRUE " | "FALSE "

<Stacking> ::= "Stacking "

<Vote> ::= "Vote "
